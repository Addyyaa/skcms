/*
 * Copyright 2018 Google Inc.
 *
 * Use of this source code is governed by a BSD-style license that can be
 * found in the LICENSE file.
 */

// Intentionally NO #pragma once... included multiple times.

// This file is included from skcms.cc in a namespace with some pre-defines:
//    - N:    depth of all vectors, 1,4,8, or 16 (preprocessor define)
//    - V<T>: a template to create a vector of N T's.

using F   = V<Color>;   // Called F for historic reasons... maybe rename C?
using I32 = V<int32_t>;
using U64 = V<uint64_t>;
using U32 = V<uint32_t>;
using U16 = V<uint16_t>;
using U8  = V<uint8_t>;


#if defined(__GNUC__) && !defined(__clang__)
    // Once again, GCC is kind of weird, not allowing vector = scalar directly.
    static constexpr F F0 = F() + 0.0f,
                       F1 = F() + 1.0f;
#else
    static constexpr F F0 = 0.0f,
                       F1 = 1.0f;
#endif

// Instead of checking __AVX__ below, we'll check USING_AVX.
// This lets skcms.cc set USING_AVX to force us in even if the compiler's not set that way.
// Same deal for __F16C__ and __AVX2__ ~~~> USING_AVX_F16C, USING_AVX2.

#if !defined(USING_AVX)      && N == 8 && defined(__AVX__)
    #define  USING_AVX
#endif
#if !defined(USING_AVX_F16C) && defined(USING_AVX) && defined(__F16C__)
    #define  USING AVX_F16C
#endif
#if !defined(USING_AVX2)     && defined(USING_AVX) && defined(__AVX2__)
    #define  USING_AVX2
#endif
#if !defined(USING_AVX512F)  && N == 16 && defined(__AVX512F__)
    #define  USING_AVX512F
#endif

// Similar to the AVX+ features, we define USING_NEON and USING_NEON_F16C.
// This is more for organizational clarity... skcms.cc doesn't force these.
#if N > 1 && defined(__ARM_NEON)
    #define USING_NEON
    #if __ARM_FP & 2
        #define USING_NEON_F16C
    #endif
    #if defined(__ARM_FEATURE_FP16_VECTOR_ARITHMETIC) && defined(SKCMS_OPT_INTO_NEON_FP16)
        #define USING_NEON_FP16
    #endif
#endif

// These -Wvector-conversion warnings seem to trigger in very bogus situations,
// like vst3q_f32() expecting a 16x char rather than a 4x float vector.  :/
#if defined(USING_NEON) && defined(__clang__)
    #pragma clang diagnostic ignored "-Wvector-conversion"
#endif

// GCC warns us about returning U64 on x86 because it's larger than a register.
// You'd see warnings like, "using AVX even though AVX is not enabled".
// We stifle these warnings... our helpers that return U64 are always inlined.
#if defined(__SSE__) && defined(__GNUC__) && !defined(__clang__)
    #pragma GCC diagnostic ignored "-Wpsabi"
#endif

#if defined(__clang__)
    #define FALLTHROUGH [[clang::fallthrough]]
#else
    #define FALLTHROUGH
#endif

// We tag most helper functions as SI, to enforce good code generation
// but also work around what we think is a bug in GCC: when targeting 32-bit
// x86, GCC tends to pass U16 (4x uint16_t vector) function arguments in the
// MMX mm0 register, which seems to mess with unrelated code that later uses
// x87 FP instructions (MMX's mm0 is an alias for x87's st0 register).
//
// It helps codegen to call __builtin_memcpy() when we know the byte count at compile time.
#if defined(__clang__) || defined(__GNUC__)
    #define SI static inline __attribute__((always_inline))
#else
    #define SI static inline
#endif

template <typename T, typename P>
SI T load(const P* ptr) {
    T val;
    small_memcpy(&val, ptr, sizeof(val));
    return val;
}
template <typename T, typename P>
SI void store(P* ptr, const T& val) {
    small_memcpy(ptr, &val, sizeof(val));
}

// (T)v is a cast when N == 1 and a bit-pun when N>1,
// so we use cast<T>(v) to actually cast or bit_pun<T>(v) to bit-pun.
template <typename D, typename S>
SI D cast(const S& v) {
#if N == 1
    return (D)v;
#elif defined(__clang__)
    return __builtin_convertvector(v, D);
#else
    D d;
    for (int i = 0; i < N; i++) {
        d[i] = v[i];
    }
    return d;
#endif
}

template <typename D, typename S>
SI D bit_pun(const S& v) {
    static_assert(sizeof(D) == sizeof(v), "");
    return load<D>(&v);
}

// When we convert from float to fixed point, it's very common to want to round,
// and for some reason compilers generate better code when converting to int32_t.
// To serve both those ends, we use this function to_fixed() instead of direct cast().
#if defined(USING_NEON_FP16)
    // NEON's got a F16 -> U16 instruction, so this should be fine without going via I16.
    SI U16 to_fixed(F f) {  return cast<U16>(f + 0.5f); }
#else
    SI U32 to_fixed(F f) {  return (U32)cast<I32>(f + 0.5f); }
#endif

template <typename C, typename T>
SI T if_then_else(C cond, T t, T e) {
#if N == 1
    return cond ? t : e;
#else
    return bit_pun<T>( ( cond & bit_pun<C>(t)) |
                       (~cond & bit_pun<C>(e)) );
#endif
}

SI F F_from_Half(U16 half) {
#if defined(USING_NEON_FP16)
    return bit_pun<F>(half);
#elif defined(USING_NEON_F16C)
    return vcvt_f32_f16((float16x4_t)half);
#elif defined(USING_AVX512F)
    return (F)_mm512_cvtph_ps((__m256i)half);
#elif defined(USING_AVX_F16C)
    typedef int16_t __attribute__((vector_size(16))) I16;
    return __builtin_ia32_vcvtph2ps256((I16)half);
#else
    U32 wide = cast<U32>(half);
    // A half is 1-5-10 sign-exponent-mantissa, with 15 exponent bias.
    U32 s  = wide & 0x8000,
        em = wide ^ s;

    // Constructing the float is easy if the half is not denormalized.
    F norm = bit_pun<F>( (s<<16) + (em<<13) + ((127-15)<<23) );

    // Simply flush all denorm half floats to zero.
    return if_then_else(em < 0x0400, F0, norm);
#endif
}

#if defined(__clang__)
    // The -((127-15)<<10) underflows that side of the math when
    // we pass a denorm half float.  It's harmless... we'll take the 0 side anyway.
    __attribute__((no_sanitize("unsigned-integer-overflow")))
#endif
SI U16 Half_from_F(F f) {
#if defined(USING_NEON_FP16)
    return bit_pun<U16>(f);
#elif defined(USING_NEON_F16C)
    return (U16)vcvt_f16_f32(f);
#elif defined(USING_AVX512F)
    return (U16)_mm512_cvtps_ph((__m512 )f, _MM_FROUND_CUR_DIRECTION );
#elif defined(USING_AVX_F16C)
    return (U16)__builtin_ia32_vcvtps2ph256(f, 0x04/*_MM_FROUND_CUR_DIRECTION*/);
#else
    // A float is 1-8-23 sign-exponent-mantissa, with 127 exponent bias.
    U32 sem = bit_pun<U32>(f),
        s   = sem & 0x80000000,
         em = sem ^ s;

    // For simplicity we flush denorm half floats (including all denorm floats) to zero.
    return cast<U16>(if_then_else(em < 0x38800000, (U32)F0
                                                 , (s>>16) + (em>>13) - ((127-15)<<10)));
#endif
}

// Swap high and low bytes of 16-bit lanes, converting between big-endian and little-endian.
#if defined(USING_NEON_FP16)
    SI U16 swap_endian_16(U16 v) {
        return (U16)vrev16q_u8((uint8x16_t) v);
    }
#elif defined(USING_NEON)
    SI U16 swap_endian_16(U16 v) {
        return (U16)vrev16_u8((uint8x8_t) v);
    }
#endif

SI U64 swap_endian_16x4(const U64& rgba) {
    return (rgba & 0x00ff00ff00ff00ff) << 8
         | (rgba & 0xff00ff00ff00ff00) >> 8;
}

#if defined(USING_NEON_FP16)
    SI F min_(F x, F y) { return (F)vminq_f16((float16x8_t)x, (float16x8_t)y); }
    SI F max_(F x, F y) { return (F)vmaxq_f16((float16x8_t)x, (float16x8_t)y); }
#elif defined(USING_NEON)
    SI F min_(F x, F y) { return (F)vminq_f32((float32x4_t)x, (float32x4_t)y); }
    SI F max_(F x, F y) { return (F)vmaxq_f32((float32x4_t)x, (float32x4_t)y); }
#else
    SI F min_(F x, F y) { return if_then_else(x > y, y, x); }
    SI F max_(F x, F y) { return if_then_else(x < y, y, x); }
#endif

SI F floor_(F x) {
#if N == 1
    return floorf_(x);
#elif defined(USING_NEON_FP16)
    return vrndmq_f16(x);
#elif defined(__aarch64__)
    return vrndmq_f32(x);
#elif defined(USING_AVX512F)
    // Clang's _mm512_floor_ps() passes its mask as -1, not (__mmask16)-1,
    // and integer santizer catches that this implicit cast changes the
    // value from -1 to 65535.  We'll cast manually to work around it.
    // Read this as `return _mm512_floor_ps(x)`.
    return _mm512_mask_floor_ps(x, (__mmask16)-1, x);
#elif defined(USING_AVX)
    return __builtin_ia32_roundps256(x, 0x01/*_MM_FROUND_FLOOR*/);
#elif defined(__SSE4_1__)
    return _mm_floor_ps(x);
#else
    // Round trip through integers with a truncating cast.
    F roundtrip = cast<F>(cast<I32>(x));
    // If x is negative, truncating gives the ceiling instead of the floor.
    return roundtrip - if_then_else(roundtrip > x, F1, F0);

    // This implementation fails for values of x that are outside
    // the range an integer can represent.  We expect most x to be small.
#endif
}

SI F approx_log2(F x) {
#if defined(USING_NEON_FP16)
    // TODO(mtklein)
    return x;
#elif defined(USING_AVX512F)
    // log2(1+X), for X in [0,1) at 10-bit precision.
    static constexpr float log2_1pX[] = {
        0.0f,
        0.00140819439281f,
        0.00281501560705f,
        0.0042204663182f,
        0.00562454919388f,
        0.00702726689397f,
        0.00842862207058f,
        0.00982861736811f,
        0.0112272554233f,
        0.0126245388651f,
        0.0140204703149f,
        0.0154150523867f,
        0.0168082876866f,
        0.0182001788132f,
        0.0195907283579f,
        0.0209799389042f,
        0.0223678130285f,
        0.0237543532994f,
        0.0251395622785f,
        0.0265234425198f,
        0.0279059965699f,
        0.0292872269682f,
        0.0306671362469f,
        0.0320457269308f,
        0.0334230015375f,
        0.0347989625773f,
        0.0361736125535f,
        0.0375469539622f,
        0.0389189892923f,
        0.0402897210257f,
        0.0416591516372f,
        0.0430272835945f,
        0.0443941193585f,
        0.0457596613827f,
        0.047123912114f,
        0.0484868739923f,
        0.0498485494506f,
        0.0512089409148f,
        0.0525680508042f,
        0.0539258815311f,
        0.0552824355012f,
        0.0566377151132f,
        0.0579917227592f,
        0.0593444608244f,
        0.0606959316876f,
        0.0620461377205f,
        0.0633950812885f,
        0.0647427647503f,
        0.0660891904578f,
        0.0674343607565f,
        0.0687782779854f,
        0.0701209444768f,
        0.0714623625566f,
        0.0728025345442f,
        0.0741414627525f,
        0.075479149488f,
        0.0768155970508f,
        0.0781508077347f,
        0.0794847838268f,
        0.0808175276083f,
        0.0821490413539f,
        0.0834793273318f,
        0.0848083878044f,
        0.0861362250273f,
        0.0874628412503f,
        0.0887882387169f,
        0.0901124196643f,
        0.0914353863236f,
        0.0927571409199f,
        0.0940776856719f,
        0.0953970227926f,
        0.0967151544885f,
        0.0980320829605f,
        0.0993478104032f,
        0.100662339005f,
        0.101975670949f,
        0.103287808412f,
        0.104598753564f,
        0.105908508571f,
        0.107217075591f,
        0.108524456778f,
        0.109830654279f,
        0.111135670235f,
        0.112439506782f,
        0.113742166049f,
        0.115043650162f,
        0.116343961237f,
        0.117643101389f,
        0.118941072724f,
        0.120237877342f,
        0.12153351734f,
        0.122827994808f,
        0.124121311829f,
        0.125413470483f,
        0.126704472843f,
        0.127994320976f,
        0.129283016945f,
        0.130570562805f,
        0.131856960609f,
        0.133142212401f,
        0.134426320221f,
        0.135709286104f,
        0.13699111208f,
        0.138271800172f,
        0.139551352399f,
        0.140829770773f,
        0.142107057303f,
        0.14338321399f,
        0.144658242832f,
        0.145932145821f,
        0.147204924942f,
        0.148476582178f,
        0.149747119505f,
        0.151016538892f,
        0.152284842307f,
        0.153552031708f,
        0.154818109052f,
        0.156083076289f,
        0.157346935363f,
        0.158609688214f,
        0.159871336778f,
        0.161131882984f,
        0.162391328757f,
        0.163649676016f,
        0.164906926676f,
        0.166163082646f,
        0.167418145832f,
        0.168672118132f,
        0.169925001442f,
        0.171176797652f,
        0.172427508645f,
        0.173677136303f,
        0.174925682501f,
        0.176173149107f,
        0.177419537989f,
        0.178664851006f,
        0.179909090015f,
        0.181152256866f,
        0.182394353405f,
        0.183635381473f,
        0.184875342908f,
        0.186114239542f,
        0.1873520732f,
        0.188588845707f,
        0.18982455888f,
        0.191059214532f,
        0.192292814471f,
        0.193525360501f,
        0.194756854422f,
        0.195987298029f,
        0.19721669311f,
        0.198445041452f,
        0.199672344836f,
        0.200898605038f,
        0.20212382383f,
        0.20334800298f,
        0.204571144249f,
        0.205793249397f,
        0.207014320178f,
        0.20823435834f,
        0.209453365629f,
        0.210671343786f,
        0.211888294546f,
        0.213104219642f,
        0.214319120801f,
        0.215532999746f,
        0.216745858195f,
        0.217957697864f,
        0.219168520462f,
        0.220378327695f,
        0.221587121265f,
        0.222794902868f,
        0.224001674198f,
        0.225207436944f,
        0.226412192789f,
        0.227615943414f,
        0.228818690496f,
        0.230020435706f,
        0.231221180711f,
        0.232420927176f,
        0.23361967676f,
        0.234817431117f,
        0.2360141919f,
        0.237209960755f,
        0.238404739325f,
        0.239598529249f,
        0.240791332162f,
        0.241983149694f,
        0.243173983473f,
        0.244363835121f,
        0.245552706256f,
        0.246740598493f,
        0.247927513444f,
        0.249113452714f,
        0.250298417906f,
        0.25148241062f,
        0.25266543245f,
        0.253847484987f,
        0.255028569819f,
        0.256208688527f,
        0.257387842693f,
        0.25856603389f,
        0.259743263691f,
        0.260919533663f,
        0.26209484537f,
        0.263269200373f,
        0.264442600227f,
        0.265615046484f,
        0.266786540695f,
        0.267957084403f,
        0.269126679149f,
        0.270295326472f,
        0.271463027904f,
        0.272629784976f,
        0.273795599214f,
        0.274960472141f,
        0.276124405274f,
        0.27728740013f,
        0.27844945822f,
        0.279610581052f,
        0.280770770131f,
        0.281930026955f,
        0.283088353024f,
        0.28424574983f,
        0.285402218862f,
        0.286557761608f,
        0.287712379549f,
        0.288866074166f,
        0.290018846933f,
        0.291170699322f,
        0.292321632802f,
        0.293471648838f,
        0.294620748892f,
        0.295768934421f,
        0.296916206879f,
        0.298062567719f,
        0.299208018387f,
        0.300352560328f,
        0.301496194983f,
        0.302638923788f,
        0.303780748177f,
        0.304921669582f,
        0.306061689428f,
        0.307200809141f,
        0.308339030139f,
        0.309476353841f,
        0.31061278166f,
        0.311748315005f,
        0.312882955284f,
        0.314016703901f,
        0.315149562256f,
        0.316281531746f,
        0.317412613765f,
        0.318542809703f,
        0.319672120947f,
        0.320800548882f,
        0.321928094887f,
        0.323054760342f,
        0.324180546619f,
        0.32530545509f,
        0.326429487122f,
        0.327552644081f,
        0.328674927328f,
        0.329796338221f,
        0.330916878115f,
        0.332036548362f,
        0.333155350311f,
        0.334273285307f,
        0.335390354694f,
        0.33650655981f,
        0.337621901993f,
        0.338736382574f,
        0.339850002885f,
        0.340962764252f,
        0.342074667999f,
        0.343185715448f,
        0.344295907916f,
        0.345405246718f,
        0.346513733166f,
        0.347621368568f,
        0.348728154231f,
        0.349834091457f,
        0.350939181546f,
        0.352043425795f,
        0.353146825498f,
        0.354249381945f,
        0.355351096425f,
        0.356451970222f,
        0.357552004618f,
        0.358651200893f,
        0.359749560322f,
        0.36084708418f,
        0.361943773735f,
        0.363039630257f,
        0.364134655008f,
        0.365228849252f,
        0.366322214246f,
        0.367414751247f,
        0.368506461508f,
        0.369597346279f,
        0.370687406807f,
        0.371776644338f,
        0.372865060113f,
        0.37395265537f,
        0.375039431347f,
        0.376125389276f,
        0.377210530389f,
        0.378294855912f,
        0.379378367071f,
        0.380461065089f,
        0.381542951185f,
        0.382624026575f,
        0.383704292474f,
        0.384783750093f,
        0.385862400641f,
        0.386940245324f,
        0.388017285345f,
        0.389093521904f,
        0.3901689562f,
        0.391243589427f,
        0.392317422779f,
        0.393390457444f,
        0.39446269461f,
        0.395534135462f,
        0.396604781182f,
        0.397674632948f,
        0.398743691938f,
        0.399811959326f,
        0.400879436282f,
        0.401946123977f,
        0.403012023575f,
        0.404077136241f,
        0.405141463136f,
        0.406205005419f,
        0.407267764245f,
        0.408329740767f,
        0.409390936138f,
        0.410451351504f,
        0.411510988012f,
        0.412569846805f,
        0.413627929024f,
        0.414685235807f,
        0.41574176829f,
        0.416797527606f,
        0.417852514886f,
        0.418906731258f,
        0.419960177848f,
        0.421012855779f,
        0.422064766173f,
        0.423115910147f,
        0.424166288818f,
        0.425215903299f,
        0.426264754702f,
        0.427312844135f,
        0.428360172704f,
        0.429406741514f,
        0.430452551666f,
        0.431497604258f,
        0.432541900388f,
        0.43358544115f,
        0.434628227637f,
        0.435670260937f,
        0.436711542137f,
        0.437752072324f,
        0.438791852578f,
        0.439830883981f,
        0.440869167611f,
        0.441906704542f,
        0.442943495849f,
        0.443979542601f,
        0.445014845868f,
        0.446049406717f,
        0.44708322621f,
        0.448116305409f,
        0.449148645375f,
        0.450180247165f,
        0.451211111832f,
        0.452241240431f,
        0.453270634011f,
        0.45429929362f,
        0.455327220305f,
        0.456354415108f,
        0.457380879073f,
        0.458406613237f,
        0.459431618637f,
        0.46045589631f,
        0.461479447286f,
        0.462502272597f,
        0.463524373271f,
        0.464545750334f,
        0.465566404809f,
        0.466586337719f,
        0.467605550083f,
        0.468624042918f,
        0.46964181724f,
        0.470658874061f,
        0.471675214392f,
        0.472690839243f,
        0.473705749619f,
        0.474719946526f,
        0.475733430966f,
        0.476746203939f,
        0.477758266444f,
        0.478769619476f,
        0.479780264029f,
        0.480790201096f,
        0.481799431666f,
        0.482807956727f,
        0.483815777264f,
        0.484822894262f,
        0.485829308702f,
        0.486835021563f,
        0.487840033823f,
        0.488844346457f,
        0.489847960439f,
        0.49085087674f,
        0.49185309633f,
        0.492854620175f,
        0.493855449241f,
        0.494855584491f,
        0.495855026887f,
        0.496853777388f,
        0.497851836951f,
        0.498849206532f,
        0.499845887083f,
        0.500841879557f,
        0.501837184902f,
        0.502831804067f,
        0.503825737996f,
        0.504818987633f,
        0.50581155392f,
        0.506803437796f,
        0.507794640199f,
        0.508785162065f,
        0.509775004327f,
        0.510764167918f,
        0.511752653767f,
        0.512740462803f,
        0.513727595952f,
        0.514714054138f,
        0.515699838284f,
        0.51668494931f,
        0.517669388134f,
        0.518653155673f,
        0.519636252843f,
        0.520618680556f,
        0.521600439724f,
        0.522581531255f,
        0.523561956057f,
        0.524541715036f,
        0.525520809095f,
        0.526499239137f,
        0.52747700606f,
        0.528454110765f,
        0.529430554146f,
        0.530406337099f,
        0.531381460516f,
        0.532355925289f,
        0.533329732306f,
        0.534302882455f,
        0.535275376621f,
        0.536247215688f,
        0.537218400539f,
        0.538188932052f,
        0.539158811108f,
        0.540128038582f,
        0.54109661535f,
        0.542064542283f,
        0.543031820255f,
        0.543998450135f,
        0.544964432789f,
        0.545929769085f,
        0.546894459888f,
        0.547858506058f,
        0.548821908459f,
        0.549784667948f,
        0.550746785383f,
        0.551708261621f,
        0.552669097514f,
        0.553629293916f,
        0.554588851678f,
        0.555547771647f,
        0.556506054672f,
        0.557463701598f,
        0.558420713269f,
        0.559377090527f,
        0.560332834212f,
        0.561287945165f,
        0.562242424221f,
        0.563196272217f,
        0.564149489986f,
        0.56510207836f,
        0.566054038171f,
        0.567005370247f,
        0.567956075415f,
        0.568906154502f,
        0.569855608331f,
        0.570804437724f,
        0.571752643504f,
        0.572700226487f,
        0.573647187493f,
        0.574593527338f,
        0.575539246835f,
        0.576484346797f,
        0.577428828036f,
        0.578372691361f,
        0.57931593758f,
        0.5802585675f,
        0.581200581925f,
        0.582141981659f,
        0.583082767503f,
        0.584022940258f,
        0.584962500721f,
        0.585901449691f,
        0.586839787962f,
        0.587777516328f,
        0.588714635582f,
        0.589651146515f,
        0.590587049915f,
        0.591522346571f,
        0.592457037268f,
        0.593391122792f,
        0.594324603925f,
        0.595257481449f,
        0.596189756144f,
        0.59712142879f,
        0.598052500162f,
        0.598982971036f,
        0.599912842187f,
        0.600842114387f,
        0.601770788408f,
        0.602698865018f,
        0.603626344986f,
        0.604553229079f,
        0.605479518062f,
        0.606405212698f,
        0.60733031375f,
        0.608254821978f,
        0.609178738142f,
        0.610102063f,
        0.611024797307f,
        0.61194694182f,
        0.612868497291f,
        0.613789464473f,
        0.614709844115f,
        0.615629636968f,
        0.616548843779f,
        0.617467465294f,
        0.618385502259f,
        0.619302955416f,
        0.620219825507f,
        0.621136113275f,
        0.622051819456f,
        0.622966944791f,
        0.623881490013f,
        0.62479545586f,
        0.625708843064f,
        0.626621652358f,
        0.627533884473f,
        0.628445540137f,
        0.62935662008f,
        0.630267125027f,
        0.631177055704f,
        0.632086412835f,
        0.632995197143f,
        0.633903409349f,
        0.634811050172f,
        0.635718120331f,
        0.636624620544f,
        0.637530551525f,
        0.63843591399f,
        0.639340708652f,
        0.640244936222f,
        0.641148597411f,
        0.642051692928f,
        0.64295422348f,
        0.643856189775f,
        0.644757592516f,
        0.645658432409f,
        0.646558710155f,
        0.647458426455f,
        0.64835758201f,
        0.649256177517f,
        0.650154213675f,
        0.651051691179f,
        0.651948610723f,
        0.652844973002f,
        0.653740778707f,
        0.654636028528f,
        0.655530723156f,
        0.656424863278f,
        0.657318449581f,
        0.658211482752f,
        0.659103963474f,
        0.65999589243f,
        0.660887270303f,
        0.661778097772f,
        0.662668375518f,
        0.663558104217f,
        0.664447284548f,
        0.665335917185f,
        0.666224002803f,
        0.667111542075f,
        0.667998535673f,
        0.668884984266f,
        0.669770888526f,
        0.670656249118f,
        0.671541066712f,
        0.672425341971f,
        0.673309075562f,
        0.674192268146f,
        0.675074920385f,
        0.675957032942f,
        0.676838606474f,
        0.677719641641f,
        0.678600139099f,
        0.679480099505f,
        0.680359523514f,
        0.681238411778f,
        0.68211676495f,
        0.682994583682f,
        0.683871868623f,
        0.684748620422f,
        0.685624839726f,
        0.686500527183f,
        0.687375683437f,
        0.688250309133f,
        0.689124404913f,
        0.689997971419f,
        0.690871009292f,
        0.691743519171f,
        0.692615501695f,
        0.693486957499f,
        0.694357887221f,
        0.695228291496f,
        0.696098170956f,
        0.696967526234f,
        0.697836357962f,
        0.69870466677f,
        0.699572453287f,
        0.700439718141f,
        0.701306461959f,
        0.702172685366f,
        0.703038388986f,
        0.703903573445f,
        0.704768239363f,
        0.705632387361f,
        0.706496018061f,
        0.707359132081f,
        0.708221730038f,
        0.70908381255f,
        0.709945380232f,
        0.710806433699f,
        0.711666973564f,
        0.71252700044f,
        0.713386514937f,
        0.714245517666f,
        0.715104009236f,
        0.715961990255f,
        0.71681946133f,
        0.717676423066f,
        0.718532876069f,
        0.719388820942f,
        0.720244258288f,
        0.721099188707f,
        0.721953612801f,
        0.72280753117f,
        0.72366094441f,
        0.72451385312f,
        0.725366257896f,
        0.726218159332f,
        0.727069558024f,
        0.727920454563f,
        0.728770849543f,
        0.729620743553f,
        0.730470137184f,
        0.731319031025f,
        0.732167425663f,
        0.733015321686f,
        0.733862719679f,
        0.734709620226f,
        0.735556023912f,
        0.736401931318f,
        0.737247343028f,
        0.73809225962f,
        0.738936681676f,
        0.739780609773f,
        0.740624044489f,
        0.741466986401f,
        0.742309436084f,
        0.743151394112f,
        0.74399286106f,
        0.7448338375f,
        0.745674324002f,
        0.746514321138f,
        0.747353829478f,
        0.748192849589f,
        0.74903138204f,
        0.749869427397f,
        0.750706986225f,
        0.751544059089f,
        0.752380646553f,
        0.753216749179f,
        0.754052367529f,
        0.754887502163f,
        0.755722153642f,
        0.756556322524f,
        0.757390009367f,
        0.758223214727f,
        0.75905593916f,
        0.759888183222f,
        0.760719947466f,
        0.761551232444f,
        0.76238203871f,
        0.763212366814f,
        0.764042217307f,
        0.764871590736f,
        0.765700487651f,
        0.766528908599f,
        0.767356854126f,
        0.768184324777f,
        0.769011321097f,
        0.769837843629f,
        0.770663892917f,
        0.771489469501f,
        0.772314573922f,
        0.77313920672f,
        0.773963368434f,
        0.774787059601f,
        0.77561028076f,
        0.776433032445f,
        0.777255315192f,
        0.778077129535f,
        0.778898476008f,
        0.779719355143f,
        0.780539767472f,
        0.781359713525f,
        0.782179193831f,
        0.78299820892f,
        0.78381675932f,
        0.784634845558f,
        0.785452468159f,
        0.786269627648f,
        0.787086324552f,
        0.787902559391f,
        0.78871833269f,
        0.78953364497f,
        0.790348496752f,
        0.791162888555f,
        0.791976820899f,
        0.792790294301f,
        0.793603309279f,
        0.79441586635f,
        0.795227966029f,
        0.79603960883f,
        0.796850795267f,
        0.797661525854f,
        0.798471801102f,
        0.799281621522f,
        0.800090987625f,
        0.80089989992f,
        0.801708358916f,
        0.802516365121f,
        0.803323919041f,
        0.804131021183f,
        0.804937672052f,
        0.805743872152f,
        0.806549621986f,
        0.807354922058f,
        0.808159772868f,
        0.808964174919f,
        0.80976812871f,
        0.810571634741f,
        0.81137469351f,
        0.812177305514f,
        0.812979471251f,
        0.813781191217f,
        0.814582465906f,
        0.815383295814f,
        0.816183681432f,
        0.816983623255f,
        0.817783121775f,
        0.818582177481f,
        0.819380790865f,
        0.820178962415f,
        0.820976692621f,
        0.821773981971f,
        0.82257083095f,
        0.823367240046f,
        0.824163209744f,
        0.824958740529f,
        0.825753832883f,
        0.826548487291f,
        0.827342704234f,
        0.828136484194f,
        0.828929827651f,
        0.829722735086f,
        0.830515206977f,
        0.831307243802f,
        0.832098846039f,
        0.832890014165f,
        0.833680748655f,
        0.834471049984f,
        0.835260918627f,
        0.836050355058f,
        0.836839359749f,
        0.837627933171f,
        0.838416075797f,
        0.839203788097f,
        0.83999107054f,
        0.840777923595f,
        0.841564347731f,
        0.842350343414f,
        0.843135911111f,
        0.843921051289f,
        0.844705764412f,
        0.845490050944f,
        0.84627391135f,
        0.847057346091f,
        0.847840355631f,
        0.848622940429f,
        0.849405100948f,
        0.850186837646f,
        0.850968150982f,
        0.851749041416f,
        0.852529509404f,
        0.853309555404f,
        0.854089179871f,
        0.85486838326f,
        0.855647166027f,
        0.856425528626f,
        0.857203471508f,
        0.857980995128f,
        0.858758099935f,
        0.859534786383f,
        0.860311054919f,
        0.861086905995f,
        0.861862340059f,
        0.862637357559f,
        0.863411958942f,
        0.864186144654f,
        0.864959915143f,
        0.865733270852f,
        0.866506212226f,
        0.86727873971f,
        0.868050853745f,
        0.868822554775f,
        0.869593843241f,
        0.870364719583f,
        0.871135184243f,
        0.871905237659f,
        0.872674880271f,
        0.873444112515f,
        0.874212934831f,
        0.874981347654f,
        0.87574935142f,
        0.876516946565f,
        0.877284133523f,
        0.878050912729f,
        0.878817284614f,
        0.879583249613f,
        0.880348808156f,
        0.881113960675f,
        0.8818787076f,
        0.882643049362f,
        0.883406986388f,
        0.884170519108f,
        0.88493364795f,
        0.885696373339f,
        0.886458695704f,
        0.887220615468f,
        0.887982133058f,
        0.888743248898f,
        0.889503963411f,
        0.890264277021f,
        0.891024190149f,
        0.891783703218f,
        0.892542816649f,
        0.893301530861f,
        0.894059846274f,
        0.894817763308f,
        0.895575282381f,
        0.89633240391f,
        0.897089128313f,
        0.897845456006f,
        0.898601387404f,
        0.899356922923f,
        0.900112062977f,
        0.900866807981f,
        0.901621158346f,
        0.902375114486f,
        0.903128676812f,
        0.903881845736f,
        0.904634621668f,
        0.905387005018f,
        0.906138996195f,
        0.906890595609f,
        0.907641803666f,
        0.908392620774f,
        0.90914304734f,
        0.90989308377f,
        0.91064273047f,
        0.911391987843f,
        0.912140856296f,
        0.91288933623f,
        0.913637428049f,
        0.914385132155f,
        0.915132448951f,
        0.915879378836f,
        0.916625922211f,
        0.917372079477f,
        0.918117851032f,
        0.918863237275f,
        0.919608238603f,
        0.920352855415f,
        0.921097088107f,
        0.921840937074f,
        0.922584402714f,
        0.923327485419f,
        0.924070185585f,
        0.924812503606f,
        0.925554439874f,
        0.926295994781f,
        0.92703716872f,
        0.927777962082f,
        0.928518375258f,
        0.929258408637f,
        0.929998062609f,
        0.930737337563f,
        0.931476233887f,
        0.932214751968f,
        0.932952892195f,
        0.933690654952f,
        0.934428040627f,
        0.935165049604f,
        0.935901682268f,
        0.936637939003f,
        0.937373820192f,
        0.938109326219f,
        0.938844457466f,
        0.939579214315f,
        0.940313597146f,
        0.941047606341f,
        0.941781242279f,
        0.942514505339f,
        0.943247395902f,
        0.943979914344f,
        0.944712061043f,
        0.945443836378f,
        0.946175240724f,
        0.946906274456f,
        0.947636937952f,
        0.948367231585f,
        0.949097155729f,
        0.949826710759f,
        0.950555897048f,
        0.951284714967f,
        0.952013164889f,
        0.952741247186f,
        0.953468962229f,
        0.954196310387f,
        0.95492329203f,
        0.955649907528f,
        0.95637615725f,
        0.957102041562f,
        0.957827560834f,
        0.958552715431f,
        0.959277505721f,
        0.960001932068f,
        0.960725994839f,
        0.961449694398f,
        0.96217303111f,
        0.962896005337f,
        0.963618617444f,
        0.964340867792f,
        0.965062756745f,
        0.965784284662f,
        0.966505451906f,
        0.967226258836f,
        0.967946705813f,
        0.968666793195f,
        0.969386521342f,
        0.970105890612f,
        0.970824901363f,
        0.971543553951f,
        0.972261848733f,
        0.972979786066f,
        0.973697366305f,
        0.974414589806f,
        0.975131456921f,
        0.975847968007f,
        0.976564123415f,
        0.9772799235f,
        0.977995368613f,
        0.978710459106f,
        0.979425195331f,
        0.980139577639f,
        0.98085360638f,
        0.981567281903f,
        0.982280604558f,
        0.982993574694f,
        0.983706192659f,
        0.984418458801f,
        0.985130373467f,
        0.985841937003f,
        0.986553149757f,
        0.987264012073f,
        0.987974524296f,
        0.988684686772f,
        0.989394499845f,
        0.990103963858f,
        0.990813079154f,
        0.991521846076f,
        0.992230264966f,
        0.992938336166f,
        0.993646060017f,
        0.994353436859f,
        0.995060467033f,
        0.995767150878f,
        0.996473488733f,
        0.997179480938f,
        0.997885127829f,
        0.998590429745f,
        0.999295387023f,
    };
    static_assert(ARRAY_COUNT(log2_1pX) == 1024, "");

    // log2(x)
    //   == log2( 2^e (1+m) )
    //   == log2( 2^e) + log2(1+m)
    //   == e + log2(1+m)

    I32 ix = (bit_pun<I32>(x) & 0x007fffff) >> (23 - 10);
    return (F)_mm512_getexp_ps(x)
         + (F)_mm512_i32gather_ps(ix, log2_1pX, 4);
#else
    // The first approximation of log2(x) is its exponent 'e', minus 127.
    I32 bits = bit_pun<I32>(x);

    F e = cast<F>(bits) * (1.0f / (1<<23));

    // If we use the mantissa too we can refine the error signficantly.
    F m = bit_pun<F>( (bits & 0x007fffff) | 0x3f000000 );

    return e - 124.225514990f
             -   1.498030302f*m
             -   1.725879990f/(0.3520887068f + m);
#endif
}

SI F approx_exp2(F x) {
#if defined(USING_NEON_FP16)
    // TODO(mtklein)
    return x;
#else
    F fract = x - floor_(x);

    I32 bits = cast<I32>((1.0f * (1<<23)) * (x + 121.274057500f
                                               -   1.490129070f*fract
                                               +  27.728023300f/(4.84252568f - fract)));
    return bit_pun<F>(bits);
#endif
}

SI F approx_pow(F x, float y) {
    return if_then_else((x == F0) | (x == F1), x
                                             , approx_exp2(approx_log2(x) * y));
}

// Return tf(x).
SI F apply_tf(const skcms_TransferFunction* tf, F x) {
#if defined(USING_NEON_FP16)
    // TODO(mtklein)
    (void)tf;
    return x;
#else
    // Peel off the sign bit and set x = |x|.
    U32 bits = bit_pun<U32>(x),
        sign = bits & 0x80000000;
    x = bit_pun<F>(bits ^ sign);

    // The transfer function has a linear part up to d, exponential at d and after.
    F v = if_then_else(x < tf->d,            tf->c*x + tf->f
                                , approx_pow(tf->a*x + tf->b, tf->g) + tf->e);

    // Tack the sign bit back on.
    return bit_pun<F>(sign | bit_pun<U32>(v));
#endif
}


// Strided loads and stores of N values, starting from p.
template <typename T, typename P>
SI T load_3(const P* p) {
#if N == 1
    return (T)p[0];
#elif N == 4
    return T{p[ 0],p[ 3],p[ 6],p[ 9]};
#elif N == 8
    return T{p[ 0],p[ 3],p[ 6],p[ 9], p[12],p[15],p[18],p[21]};
#elif N == 16
    return T{p[ 0],p[ 3],p[ 6],p[ 9], p[12],p[15],p[18],p[21],
             p[24],p[27],p[30],p[33], p[36],p[39],p[42],p[45]};
#endif
}

template <typename T, typename P>
SI T load_4(const P* p) {
#if N == 1
    return (T)p[0];
#elif N == 4
    return T{p[ 0],p[ 4],p[ 8],p[12]};
#elif N == 8
    return T{p[ 0],p[ 4],p[ 8],p[12], p[16],p[20],p[24],p[28]};
#elif N == 16
    return T{p[ 0],p[ 4],p[ 8],p[12], p[16],p[20],p[24],p[28],
             p[32],p[36],p[40],p[44], p[48],p[52],p[56],p[60]};
#endif
}

template <typename T, typename P>
SI void store_3(P* p, const T& v) {
#if N == 1
    p[0] = v;
#elif N == 4
    p[ 0] = v[ 0]; p[ 3] = v[ 1]; p[ 6] = v[ 2]; p[ 9] = v[ 3];
#elif N == 8
    p[ 0] = v[ 0]; p[ 3] = v[ 1]; p[ 6] = v[ 2]; p[ 9] = v[ 3];
    p[12] = v[ 4]; p[15] = v[ 5]; p[18] = v[ 6]; p[21] = v[ 7];
#elif N == 16
    p[ 0] = v[ 0]; p[ 3] = v[ 1]; p[ 6] = v[ 2]; p[ 9] = v[ 3];
    p[12] = v[ 4]; p[15] = v[ 5]; p[18] = v[ 6]; p[21] = v[ 7];
    p[24] = v[ 8]; p[27] = v[ 9]; p[30] = v[10]; p[33] = v[11];
    p[36] = v[12]; p[39] = v[13]; p[42] = v[14]; p[45] = v[15];
#endif
}

template <typename T, typename P>
SI void store_4(P* p, const T& v) {
#if N == 1
    p[0] = v;
#elif N == 4
    p[ 0] = v[ 0]; p[ 4] = v[ 1]; p[ 8] = v[ 2]; p[12] = v[ 3];
#elif N == 8
    p[ 0] = v[ 0]; p[ 4] = v[ 1]; p[ 8] = v[ 2]; p[12] = v[ 3];
    p[16] = v[ 4]; p[20] = v[ 5]; p[24] = v[ 6]; p[28] = v[ 7];
#elif N == 16
    p[ 0] = v[ 0]; p[ 4] = v[ 1]; p[ 8] = v[ 2]; p[12] = v[ 3];
    p[16] = v[ 4]; p[20] = v[ 5]; p[24] = v[ 6]; p[28] = v[ 7];
    p[32] = v[ 8]; p[36] = v[ 9]; p[40] = v[10]; p[44] = v[11];
    p[48] = v[12]; p[52] = v[13]; p[56] = v[14]; p[60] = v[15];
#endif
}


SI U8 gather_8(const uint8_t* p, I32 ix) {
#if N == 1
    U8 v = p[ix];
#elif N == 4
    U8 v = { p[ix[0]], p[ix[1]], p[ix[2]], p[ix[3]] };
#elif N == 8
    U8 v = { p[ix[0]], p[ix[1]], p[ix[2]], p[ix[3]],
             p[ix[4]], p[ix[5]], p[ix[6]], p[ix[7]] };
#elif N == 16
    U8 v = { p[ix[ 0]], p[ix[ 1]], p[ix[ 2]], p[ix[ 3]],
             p[ix[ 4]], p[ix[ 5]], p[ix[ 6]], p[ix[ 7]],
             p[ix[ 8]], p[ix[ 9]], p[ix[10]], p[ix[11]],
             p[ix[12]], p[ix[13]], p[ix[14]], p[ix[15]] };
#endif
    return v;
}

SI U16 gather_16(const uint8_t* p, I32 ix) {
    // Load the i'th 16-bit value from p.
    auto load_16 = [p](int i) {
        return load<uint16_t>(p + 2*i);
    };
#if N == 1
    U16 v = load_16(ix);
#elif N == 4
    U16 v = { load_16(ix[0]), load_16(ix[1]), load_16(ix[2]), load_16(ix[3]) };
#elif N == 8
    U16 v = { load_16(ix[0]), load_16(ix[1]), load_16(ix[2]), load_16(ix[3]),
              load_16(ix[4]), load_16(ix[5]), load_16(ix[6]), load_16(ix[7]) };
#elif N == 16
    U16 v = { load_16(ix[ 0]), load_16(ix[ 1]), load_16(ix[ 2]), load_16(ix[ 3]),
              load_16(ix[ 4]), load_16(ix[ 5]), load_16(ix[ 6]), load_16(ix[ 7]),
              load_16(ix[ 8]), load_16(ix[ 9]), load_16(ix[10]), load_16(ix[11]),
              load_16(ix[12]), load_16(ix[13]), load_16(ix[14]), load_16(ix[15]) };
#endif
    return v;
}

SI U32 gather_32(const uint8_t* p, I32 ix) {
    // Load the i'th 32-bit value from p.
    auto load_32 = [p](int i) {
        return load<uint32_t>(p + 4*i);
    };
#if N == 1
    U32 v = load_32(ix);
#elif N == 4
    U32 v = { load_32(ix[0]), load_32(ix[1]), load_32(ix[2]), load_32(ix[3]) };
#elif N == 8
    U32 v = { load_32(ix[0]), load_32(ix[1]), load_32(ix[2]), load_32(ix[3]),
              load_32(ix[4]), load_32(ix[5]), load_32(ix[6]), load_32(ix[7]) };
#elif N == 16
    U32 v = { load_32(ix[ 0]), load_32(ix[ 1]), load_32(ix[ 2]), load_32(ix[ 3]),
              load_32(ix[ 4]), load_32(ix[ 5]), load_32(ix[ 6]), load_32(ix[ 7]),
              load_32(ix[ 8]), load_32(ix[ 9]), load_32(ix[10]), load_32(ix[11]),
              load_32(ix[12]), load_32(ix[13]), load_32(ix[14]), load_32(ix[15]) };
#endif
    // TODO: AVX2 and AVX-512 gathers (c.f. gather_24).
    return v;
}

SI U32 gather_24(const uint8_t* p, I32 ix) {
    // First, back up a byte.  Any place we're gathering from has a safe junk byte to read
    // in front of it, either a previous table value, or some tag metadata.
    p -= 1;

    // Load the i'th 24-bit value from p, and 1 extra byte.
    auto load_24_32 = [p](int i) {
        return load<uint32_t>(p + 3*i);
    };

    // Now load multiples of 4 bytes (a junk byte, then r,g,b).
#if N == 1
    U32 v = load_24_32(ix);
#elif N == 4
    U32 v = { load_24_32(ix[0]), load_24_32(ix[1]), load_24_32(ix[2]), load_24_32(ix[3]) };
#elif N == 8 && !defined(USING_AVX2)
    U32 v = { load_24_32(ix[0]), load_24_32(ix[1]), load_24_32(ix[2]), load_24_32(ix[3]),
              load_24_32(ix[4]), load_24_32(ix[5]), load_24_32(ix[6]), load_24_32(ix[7]) };
#elif N == 8
    (void)load_24_32;
    // The gather instruction here doesn't need any particular alignment,
    // but the intrinsic takes a const int*.
    const int* p4 = bit_pun<const int*>(p);
    I32 zero = { 0, 0, 0, 0,  0, 0, 0, 0},
        mask = {-1,-1,-1,-1, -1,-1,-1,-1};
    #if defined(__clang__)
        U32 v = (U32)__builtin_ia32_gatherd_d256(zero, p4, 3*ix, mask, 1);
    #elif defined(__GNUC__)
        U32 v = (U32)__builtin_ia32_gathersiv8si(zero, p4, 3*ix, mask, 1);
    #endif
#elif N == 16
    (void)load_24_32;
    // The intrinsic is supposed to take const void* now, but it takes const int*, just like AVX2.
    // And AVX-512 swapped the order of arguments.  :/
    const int* p4 = bit_pun<const int*>(p);
    U32 v = (U32)_mm512_i32gather_epi32((__m512i)(3*ix), p4, 1);
#endif

    // Shift off the junk byte, leaving r,g,b in low 24 bits (and zero in the top 8).
    return v >> 8;
}

#if !defined(__arm__)
    SI void gather_48(const uint8_t* p, I32 ix, U64* v) {
        // As in gather_24(), with everything doubled.
        p -= 2;

        // Load the i'th 48-bit value from p, and 2 extra bytes.
        auto load_48_64 = [p](int i) {
            return load<uint64_t>(p + 6*i);
        };

    #if N == 1
        *v = load_48_64(ix);
    #elif N == 4
        *v = U64{
            load_48_64(ix[0]), load_48_64(ix[1]), load_48_64(ix[2]), load_48_64(ix[3]),
        };
    #elif N == 8 && !defined(USING_AVX2)
        *v = U64{
            load_48_64(ix[0]), load_48_64(ix[1]), load_48_64(ix[2]), load_48_64(ix[3]),
            load_48_64(ix[4]), load_48_64(ix[5]), load_48_64(ix[6]), load_48_64(ix[7]),
        };
    #elif N == 8
        (void)load_48_64;
        typedef int32_t   __attribute__((vector_size(16))) Half_I32;
        typedef long long __attribute__((vector_size(32))) Half_I64;

        // The gather instruction here doesn't need any particular alignment,
        // but the intrinsic takes a const long long*.
        const long long int* p8 = bit_pun<const long long int*>(p);

        Half_I64 zero = { 0, 0, 0, 0},
                 mask = {-1,-1,-1,-1};

        ix *= 6;
        Half_I32 ix_lo = { ix[0], ix[1], ix[2], ix[3] },
                 ix_hi = { ix[4], ix[5], ix[6], ix[7] };

        #if defined(__clang__)
            Half_I64 lo = (Half_I64)__builtin_ia32_gatherd_q256(zero, p8, ix_lo, mask, 1),
                     hi = (Half_I64)__builtin_ia32_gatherd_q256(zero, p8, ix_hi, mask, 1);
        #elif defined(__GNUC__)
            Half_I64 lo = (Half_I64)__builtin_ia32_gathersiv4di(zero, p8, ix_lo, mask, 1),
                     hi = (Half_I64)__builtin_ia32_gathersiv4di(zero, p8, ix_hi, mask, 1);
        #endif
        store((char*)v +  0, lo);
        store((char*)v + 32, hi);
    #elif N == 16
        (void)load_48_64;
        const long long int* p8 = bit_pun<const long long int*>(p);
        __m512i lo = _mm512_i32gather_epi64(_mm512_extracti32x8_epi32((__m512i)(6*ix), 0), p8, 1),
                hi = _mm512_i32gather_epi64(_mm512_extracti32x8_epi32((__m512i)(6*ix), 1), p8, 1);
        store((char*)v +  0, lo);
        store((char*)v + 64, hi);
    #endif

        *v >>= 16;
    }
#endif

SI F F_from_U8(U8 v) {
    return cast<F>(v) * (1/255.0f);
}

SI F F_from_U16_BE(U16 v) {
    // All 16-bit ICC values are big-endian, so we byte swap before converting to float.
    // MSVC catches the "loss" of data here in the portable path, so we also make sure to mask.
    v = (U16)( ((v<<8)|(v>>8)) & 0xffff );
    return cast<F>(v) * (1/65535.0f);
}

SI U16 U16_from_F(F v) {
    // 65535 == inf in FP16, so promote to FP32 before converting.
    return cast<U16>(cast<V<float>>(v) * 65535 + 0.5f);
}

SI F minus_1_ulp(F v) {
#if defined(USING_NEON_FP16)
    return bit_pun<F>( bit_pun<U16>(v) - 1 );
#else
    return bit_pun<F>( bit_pun<U32>(v) - 1 );
#endif
}

SI F table(const skcms_Curve* curve, F v) {
    // Clamp the input to [0,1], then scale to a table index.
    F ix = max_(F0, min_(v, F1)) * (float)(curve->table_entries - 1);

    // We'll look up (equal or adjacent) entries at lo and hi, then lerp by t between the two.
    I32 lo = cast<I32>(            ix      ),
        hi = cast<I32>(minus_1_ulp(ix+1.0f));
    F t = ix - cast<F>(lo);  // i.e. the fractional part of ix.

    // TODO: can we load l and h simultaneously?  Each entry in 'h' is either
    // the same as in 'l' or adjacent.  We have a rough idea that's it'd always be safe
    // to read adjacent entries and perhaps underflow the table by a byte or two
    // (it'd be junk, but always safe to read).  Not sure how to lerp yet.
    F l,h;
    if (curve->table_8) {
        l = F_from_U8(gather_8(curve->table_8, lo));
        h = F_from_U8(gather_8(curve->table_8, hi));
    } else {
        l = F_from_U16_BE(gather_16(curve->table_16, lo));
        h = F_from_U16_BE(gather_16(curve->table_16, hi));
    }
    return l + (h-l)*t;
}

SI void sample_clut_8(const skcms_A2B* a2b, I32 ix, F* r, F* g, F* b) {
    U32 rgb = gather_24(a2b->grid_8, ix);

    *r = cast<F>((rgb >>  0) & 0xff) * (1/255.0f);
    *g = cast<F>((rgb >>  8) & 0xff) * (1/255.0f);
    *b = cast<F>((rgb >> 16) & 0xff) * (1/255.0f);
}

SI void sample_clut_16(const skcms_A2B* a2b, I32 ix, F* r, F* g, F* b) {
#if defined(__arm__)
    // This is up to 2x faster on 32-bit ARM than the #else-case fast path.
    *r = F_from_U16_BE(gather_16(a2b->grid_16, 3*ix+0));
    *g = F_from_U16_BE(gather_16(a2b->grid_16, 3*ix+1));
    *b = F_from_U16_BE(gather_16(a2b->grid_16, 3*ix+2));
#else
    // This strategy is much faster for 64-bit builds, and fine for 32-bit x86 too.
    U64 rgb;
    gather_48(a2b->grid_16, ix, &rgb);
    rgb = swap_endian_16x4(rgb);

    *r = cast<F>((rgb >>  0) & 0xffff) * (1/65535.0f);
    *g = cast<F>((rgb >> 16) & 0xffff) * (1/65535.0f);
    *b = cast<F>((rgb >> 32) & 0xffff) * (1/65535.0f);
#endif
}

// GCC 7.2.0 hits an internal compiler error with -finline-functions (or -O3)
// when targeting MIPS 64,  I think attempting to inline clut() into exec_ops().
#if 1 && defined(__GNUC__) && !defined(__clang__) && defined(__mips64)
    #define MAYBE_NOINLINE __attribute__((noinline))
#else
    #define MAYBE_NOINLINE
#endif

MAYBE_NOINLINE
static void clut(const skcms_A2B* a2b, F* r, F* g, F* b, F a) {
    const int dim = (int)a2b->input_channels;
    assert (0 < dim && dim <= 4);

    // For each of these arrays, think foo[2*dim], but we use foo[8] since we know dim <= 4.
    I32 index [8];  // Index contribution by dimension, first low from 0, then high from 4.
    F   weight[8];  // Weight for each contribution, again first low, then high.

    // O(dim) work first: calculate index,weight from r,g,b,a.
    const F inputs[] = { *r,*g,*b,a };
    for (int i = dim-1, stride = 1; i >= 0; i--) {
        // x is where we logically want to sample the grid in the i-th dimension.
        F x = inputs[i] * (float)(a2b->grid_points[i] - 1);

        // But we can't index at floats.  lo and hi are the two integer grid points surrounding x.
        I32 lo = cast<I32>(            x      ),   // i.e. trunc(x) == floor(x) here.
            hi = cast<I32>(minus_1_ulp(x+1.0f));
        // Notice how we fold in the accumulated stride across previous dimensions here.
        index[i+0] = lo * stride;
        index[i+4] = hi * stride;
        stride *= a2b->grid_points[i];

        // We'll interpolate between those two integer grid points by t.
        F t = x - cast<F>(lo);  // i.e. fract(x)
        weight[i+0] = 1-t;
        weight[i+4] = t;
    }

    *r = *g = *b = F0;

    // We'll sample 2^dim == 1<<dim table entries per pixel,
    // in all combinations of low and high in each dimension.
    for (int combo = 0; combo < (1<<dim); combo++) {  // This loop can be done in any order.

        // Each of these upcoming (combo&N)*K expressions here evaluates to 0 or 4,
        // where 0 selects the low index contribution and its weight 1-t,
        // or 4 the high index contribution and its weight t.

        // Since 0<dim≤4, we can always just start off with the 0-th channel,
        // then handle the others conditionally.
        I32 ix = index [0 + (combo&1)*4];
        F    w = weight[0 + (combo&1)*4];

        switch ((dim-1)&3) {  // This lets the compiler know there are no other cases to handle.
            case 3: ix += index [3 + (combo&8)/2];
                    w  *= weight[3 + (combo&8)/2];
                    FALLTHROUGH;
                    // fall through

            case 2: ix += index [2 + (combo&4)*1];
                    w  *= weight[2 + (combo&4)*1];
                    FALLTHROUGH;
                    // fall through

            case 1: ix += index [1 + (combo&2)*2];
                    w  *= weight[1 + (combo&2)*2];
        }

        F R,G,B;
        if (a2b->grid_8) {
            sample_clut_8 (a2b,ix, &R,&G,&B);
        } else {
            sample_clut_16(a2b,ix, &R,&G,&B);
        }

        *r += w*R;
        *g += w*G;
        *b += w*B;
    }
}

static void exec_ops(const Op* ops, const void** args,
                     const char* src, char* dst, int i) {
    F r = F0, g = F0, b = F0, a = F1;
    while (true) {
        switch (*ops++) {
            case Op_load_a8:{
                a = F_from_U8(load<U8>(src + 1*i));
            } break;

            case Op_load_g8:{
                r = g = b = F_from_U8(load<U8>(src + 1*i));
            } break;

            case Op_load_4444:{
                U16 abgr = load<U16>(src + 2*i);

                r = cast<F>((abgr >> 12) & 0xf) * (1/15.0f);
                g = cast<F>((abgr >>  8) & 0xf) * (1/15.0f);
                b = cast<F>((abgr >>  4) & 0xf) * (1/15.0f);
                a = cast<F>((abgr >>  0) & 0xf) * (1/15.0f);
            } break;

            case Op_load_565:{
                U16 rgb = load<U16>(src + 2*i);

                r = cast<F>(rgb & (uint16_t)(31<< 0)) * (1.0f / (31<< 0));
                g = cast<F>(rgb & (uint16_t)(63<< 5)) * (1.0f / (63<< 5));
                b = cast<F>(rgb & (uint16_t)(31<<11)) * (1.0f / (31<<11));
            } break;

            case Op_load_888:{
                const uint8_t* rgb = (const uint8_t*)(src + 3*i);
            #if defined(USING_NEON_FP16)
                // See the explanation under USING_NEON below.  This is that doubled up.
                uint8x16x3_t v = {{ vdupq_n_u8(0), vdupq_n_u8(0), vdupq_n_u8(0) }};
                v = vld3q_lane_u8(rgb+ 0, v,  0);
                v = vld3q_lane_u8(rgb+ 3, v,  2);
                v = vld3q_lane_u8(rgb+ 6, v,  4);
                v = vld3q_lane_u8(rgb+ 9, v,  6);

                v = vld3q_lane_u8(rgb+12, v,  8);
                v = vld3q_lane_u8(rgb+15, v, 10);
                v = vld3q_lane_u8(rgb+18, v, 12);
                v = vld3q_lane_u8(rgb+21, v, 14);

                r = cast<F>((U16)v.val[0]) * (1/255.0f);
                g = cast<F>((U16)v.val[1]) * (1/255.0f);
                b = cast<F>((U16)v.val[2]) * (1/255.0f);
            #elif defined(USING_NEON)
                // There's no uint8x4x3_t or vld3 load for it, so we'll load each rgb pixel one at
                // a time.  Since we're doing that, we might as well load them into 16-bit lanes.
                // (We'd even load into 32-bit lanes, but that's not possible on ARMv7.)
                uint8x8x3_t v = {{ vdup_n_u8(0), vdup_n_u8(0), vdup_n_u8(0) }};
                v = vld3_lane_u8(rgb+0, v, 0);
                v = vld3_lane_u8(rgb+3, v, 2);
                v = vld3_lane_u8(rgb+6, v, 4);
                v = vld3_lane_u8(rgb+9, v, 6);

                // Now if we squint, those 3 uint8x8_t we constructed are really U16s, easy to
                // convert to F.  (Again, U32 would be even better here if drop ARMv7 or split
                // ARMv7 and ARMv8 impls.)
                r = cast<F>((U16)v.val[0]) * (1/255.0f);
                g = cast<F>((U16)v.val[1]) * (1/255.0f);
                b = cast<F>((U16)v.val[2]) * (1/255.0f);
            #else
                r = cast<F>(load_3<U32>(rgb+0) ) * (1/255.0f);
                g = cast<F>(load_3<U32>(rgb+1) ) * (1/255.0f);
                b = cast<F>(load_3<U32>(rgb+2) ) * (1/255.0f);
            #endif
            } break;

            case Op_load_8888:{
                U32 rgba = load<U32>(src + 4*i);

                r = cast<F>((rgba >>  0) & 0xff) * (1/255.0f);
                g = cast<F>((rgba >>  8) & 0xff) * (1/255.0f);
                b = cast<F>((rgba >> 16) & 0xff) * (1/255.0f);
                a = cast<F>((rgba >> 24) & 0xff) * (1/255.0f);
            } break;

            case Op_load_8888_palette8:{
                const uint8_t* palette = (const uint8_t*) *args++;
                I32 ix = cast<I32>(load<U8>(src + 1*i));
                U32 rgba = gather_32(palette, ix);

                r = cast<F>((rgba >>  0) & 0xff) * (1/255.0f);
                g = cast<F>((rgba >>  8) & 0xff) * (1/255.0f);
                b = cast<F>((rgba >> 16) & 0xff) * (1/255.0f);
                a = cast<F>((rgba >> 24) & 0xff) * (1/255.0f);
            } break;

            case Op_load_1010102:{
                U32 rgba = load<U32>(src + 4*i);

                r = cast<F>((rgba >>  0) & 0x3ff) * (1/1023.0f);
                g = cast<F>((rgba >> 10) & 0x3ff) * (1/1023.0f);
                b = cast<F>((rgba >> 20) & 0x3ff) * (1/1023.0f);
                a = cast<F>((rgba >> 30) & 0x3  ) * (1/   3.0f);
            } break;

            case Op_load_161616LE:{
                uintptr_t ptr = (uintptr_t)(src + 6*i);
                assert( (ptr & 1) == 0 );                   // src must be 2-byte aligned for this
                const uint16_t* rgb = (const uint16_t*)ptr; // cast to const uint16_t* to be safe.
            #if defined(USING_NEON_FP16)
                uint16x8x3_t v = vld3q_u16(rgb);
                r = cast<F>((U16)v.val[0]) * (1/65535.0f);
                g = cast<F>((U16)v.val[1]) * (1/65535.0f);
                b = cast<F>((U16)v.val[2]) * (1/65535.0f);
            #elif defined(USING_NEON)
                uint16x4x3_t v = vld3_u16(rgb);
                r = cast<F>((U16)v.val[0]) * (1/65535.0f);
                g = cast<F>((U16)v.val[1]) * (1/65535.0f);
                b = cast<F>((U16)v.val[2]) * (1/65535.0f);
            #else
                r = cast<F>(load_3<U32>(rgb+0)) * (1/65535.0f);
                g = cast<F>(load_3<U32>(rgb+1)) * (1/65535.0f);
                b = cast<F>(load_3<U32>(rgb+2)) * (1/65535.0f);
            #endif
            } break;

            case Op_load_16161616LE:{
                uintptr_t ptr = (uintptr_t)(src + 8*i);
                assert( (ptr & 1) == 0 );                    // src must be 2-byte aligned for this
                const uint16_t* rgba = (const uint16_t*)ptr; // cast to const uint16_t* to be safe.
            #if defined(USING_NEON_FP16)
                uint16x8x4_t v = vld4q_u16(rgba);
                r = cast<F>((U16)v.val[0]) * (1/65535.0f);
                g = cast<F>((U16)v.val[1]) * (1/65535.0f);
                b = cast<F>((U16)v.val[2]) * (1/65535.0f);
                a = cast<F>((U16)v.val[3]) * (1/65535.0f);
            #elif defined(USING_NEON)
                uint16x4x4_t v = vld4_u16(rgba);
                r = cast<F>((U16)v.val[0]) * (1/65535.0f);
                g = cast<F>((U16)v.val[1]) * (1/65535.0f);
                b = cast<F>((U16)v.val[2]) * (1/65535.0f);
                a = cast<F>((U16)v.val[3]) * (1/65535.0f);
            #else
                U64 px = load<U64>(rgba);

                r = cast<F>((px >>  0) & 0xffff) * (1/65535.0f);
                g = cast<F>((px >> 16) & 0xffff) * (1/65535.0f);
                b = cast<F>((px >> 32) & 0xffff) * (1/65535.0f);
                a = cast<F>((px >> 48) & 0xffff) * (1/65535.0f);
            #endif
            } break;

            case Op_load_161616BE:{
                uintptr_t ptr = (uintptr_t)(src + 6*i);
                assert( (ptr & 1) == 0 );                   // src must be 2-byte aligned for this
                const uint16_t* rgb = (const uint16_t*)ptr; // cast to const uint16_t* to be safe.
            #if defined(USING_NEON_FP16)
                uint16x8x3_t v = vld3q_u16(rgb);
                r = cast<F>(swap_endian_16((U16)v.val[0])) * (1/65535.0f);
                g = cast<F>(swap_endian_16((U16)v.val[1])) * (1/65535.0f);
                b = cast<F>(swap_endian_16((U16)v.val[2])) * (1/65535.0f);
            #elif defined(USING_NEON)
                uint16x4x3_t v = vld3_u16(rgb);
                r = cast<F>(swap_endian_16((U16)v.val[0])) * (1/65535.0f);
                g = cast<F>(swap_endian_16((U16)v.val[1])) * (1/65535.0f);
                b = cast<F>(swap_endian_16((U16)v.val[2])) * (1/65535.0f);
            #else
                U32 R = load_3<U32>(rgb+0),
                    G = load_3<U32>(rgb+1),
                    B = load_3<U32>(rgb+2);
                // R,G,B are big-endian 16-bit, so byte swap them before converting to float.
                r = cast<F>((R & 0x00ff)<<8 | (R & 0xff00)>>8) * (1/65535.0f);
                g = cast<F>((G & 0x00ff)<<8 | (G & 0xff00)>>8) * (1/65535.0f);
                b = cast<F>((B & 0x00ff)<<8 | (B & 0xff00)>>8) * (1/65535.0f);
            #endif
            } break;

            case Op_load_16161616BE:{
                uintptr_t ptr = (uintptr_t)(src + 8*i);
                assert( (ptr & 1) == 0 );                    // src must be 2-byte aligned for this
                const uint16_t* rgba = (const uint16_t*)ptr; // cast to const uint16_t* to be safe.
            #if defined(USING_NEON_FP16)
                uint16x8x4_t v = vld4q_u16(rgba);
                r = cast<F>(swap_endian_16((U16)v.val[0])) * (1/65535.0f);
                g = cast<F>(swap_endian_16((U16)v.val[1])) * (1/65535.0f);
                b = cast<F>(swap_endian_16((U16)v.val[2])) * (1/65535.0f);
                a = cast<F>(swap_endian_16((U16)v.val[3])) * (1/65535.0f);
            #elif defined(USING_NEON)
                uint16x4x4_t v = vld4_u16(rgba);
                r = cast<F>(swap_endian_16((U16)v.val[0])) * (1/65535.0f);
                g = cast<F>(swap_endian_16((U16)v.val[1])) * (1/65535.0f);
                b = cast<F>(swap_endian_16((U16)v.val[2])) * (1/65535.0f);
                a = cast<F>(swap_endian_16((U16)v.val[3])) * (1/65535.0f);
            #else
                U64 px = swap_endian_16x4(load<U64>(rgba));

                r = cast<F>((px >>  0) & 0xffff) * (1/65535.0f);
                g = cast<F>((px >> 16) & 0xffff) * (1/65535.0f);
                b = cast<F>((px >> 32) & 0xffff) * (1/65535.0f);
                a = cast<F>((px >> 48) & 0xffff) * (1/65535.0f);
            #endif
            } break;

            case Op_load_hhh:{
                uintptr_t ptr = (uintptr_t)(src + 6*i);
                assert( (ptr & 1) == 0 );                   // src must be 2-byte aligned for this
                const uint16_t* rgb = (const uint16_t*)ptr; // cast to const uint16_t* to be safe.
            #if defined(USING_NEON_FP16)
                uint16x8x3_t v = vld3q_u16(rgb);
                U16 R = (U16)v.val[0],
                    G = (U16)v.val[1],
                    B = (U16)v.val[2];
            #elif defined(USING_NEON)
                uint16x4x3_t v = vld3_u16(rgb);
                U16 R = (U16)v.val[0],
                    G = (U16)v.val[1],
                    B = (U16)v.val[2];
            #else
                U16 R = load_3<U16>(rgb+0),
                    G = load_3<U16>(rgb+1),
                    B = load_3<U16>(rgb+2);
            #endif
                r = F_from_Half(R);
                g = F_from_Half(G);
                b = F_from_Half(B);
            } break;

            case Op_load_hhhh:{
                uintptr_t ptr = (uintptr_t)(src + 8*i);
                assert( (ptr & 1) == 0 );                    // src must be 2-byte aligned for this
                const uint16_t* rgba = (const uint16_t*)ptr; // cast to const uint16_t* to be safe.
            #if defined(USING_NEON_FP16)
                uint16x8x4_t v = vld4q_u16(rgba);
                U16 R = (U16)v.val[0],
                    G = (U16)v.val[1],
                    B = (U16)v.val[2],
                    A = (U16)v.val[3];
            #elif defined(USING_NEON)
                uint16x4x4_t v = vld4_u16(rgba);
                U16 R = (U16)v.val[0],
                    G = (U16)v.val[1],
                    B = (U16)v.val[2],
                    A = (U16)v.val[3];
            #else
                U64 px = load<U64>(rgba);
                U16 R = cast<U16>((px >>  0) & 0xffff),
                    G = cast<U16>((px >> 16) & 0xffff),
                    B = cast<U16>((px >> 32) & 0xffff),
                    A = cast<U16>((px >> 48) & 0xffff);
            #endif
                r = F_from_Half(R);
                g = F_from_Half(G);
                b = F_from_Half(B);
                a = F_from_Half(A);
            } break;

            case Op_load_fff:{
                uintptr_t ptr = (uintptr_t)(src + 12*i);
                assert( (ptr & 3) == 0 );                   // src must be 4-byte aligned for this
                const float* rgb = (const float*)ptr;       // cast to const float* to be safe.
            #if defined(USING_NEON_FP16)
                float32x4x3_t lo = vld3q_f32(rgb +  0),
                              hi = vld3q_f32(rgb + 12);
                r = (F)vcombine_f16(vcvt_f16_f32(lo.val[0]), vcvt_f16_f32(hi.val[0]));
                g = (F)vcombine_f16(vcvt_f16_f32(lo.val[1]), vcvt_f16_f32(hi.val[1]));
                b = (F)vcombine_f16(vcvt_f16_f32(lo.val[2]), vcvt_f16_f32(hi.val[2]));
            #elif defined(USING_NEON)
                float32x4x3_t v = vld3q_f32(rgb);
                r = (F)v.val[0];
                g = (F)v.val[1];
                b = (F)v.val[2];
            #else
                r = load_3<F>(rgb+0);
                g = load_3<F>(rgb+1);
                b = load_3<F>(rgb+2);
            #endif
            } break;

            case Op_load_ffff:{
                uintptr_t ptr = (uintptr_t)(src + 16*i);
                assert( (ptr & 3) == 0 );                   // src must be 4-byte aligned for this
                const float* rgba = (const float*)ptr;      // cast to const float* to be safe.
            #if defined(USING_NEON_FP16)
                float32x4x4_t lo = vld4q_f32(rgba +  0),
                              hi = vld4q_f32(rgba + 16);
                r = (F)vcombine_f16(vcvt_f16_f32(lo.val[0]), vcvt_f16_f32(hi.val[0]));
                g = (F)vcombine_f16(vcvt_f16_f32(lo.val[1]), vcvt_f16_f32(hi.val[1]));
                b = (F)vcombine_f16(vcvt_f16_f32(lo.val[2]), vcvt_f16_f32(hi.val[2]));
                a = (F)vcombine_f16(vcvt_f16_f32(lo.val[3]), vcvt_f16_f32(hi.val[3]));
            #elif defined(USING_NEON)
                float32x4x4_t v = vld4q_f32(rgba);
                r = (F)v.val[0];
                g = (F)v.val[1];
                b = (F)v.val[2];
                a = (F)v.val[3];
            #else
                r = load_4<F>(rgba+0);
                g = load_4<F>(rgba+1);
                b = load_4<F>(rgba+2);
                a = load_4<F>(rgba+3);
            #endif
            } break;

            case Op_swap_rb:{
                F t = r;
                r = b;
                b = t;
            } break;

            case Op_clamp:{
                r = max_(F0, min_(r, F1));
                g = max_(F0, min_(g, F1));
                b = max_(F0, min_(b, F1));
                a = max_(F0, min_(a, F1));
            } break;

            case Op_invert:{
                r = F1 - r;
                g = F1 - g;
                b = F1 - b;
                a = F1 - a;
            } break;

            case Op_force_opaque:{
                a = F1;
            } break;

            case Op_premul:{
                r *= a;
                g *= a;
                b *= a;
            } break;

            case Op_unpremul:{
                F scale = if_then_else(F1 / a < INFINITY_, F1 / a, F0);
                r *= scale;
                g *= scale;
                b *= scale;
            } break;

            case Op_matrix_3x3:{
                const skcms_Matrix3x3* matrix = (const skcms_Matrix3x3*) *args++;
                const float* m = &matrix->vals[0][0];

                F R = m[0]*r + m[1]*g + m[2]*b,
                  G = m[3]*r + m[4]*g + m[5]*b,
                  B = m[6]*r + m[7]*g + m[8]*b;

                r = R;
                g = G;
                b = B;
            } break;

            case Op_matrix_3x4:{
                const skcms_Matrix3x4* matrix = (const skcms_Matrix3x4*) *args++;
                const float* m = &matrix->vals[0][0];

                F R = m[0]*r + m[1]*g + m[ 2]*b + m[ 3],
                  G = m[4]*r + m[5]*g + m[ 6]*b + m[ 7],
                  B = m[8]*r + m[9]*g + m[10]*b + m[11];

                r = R;
                g = G;
                b = B;
            } break;

            case Op_lab_to_xyz:{
                // The L*a*b values are in r,g,b, but normalized to [0,1].  Reconstruct them:
                F L = r * 100.0f,
                  A = g * 255.0f - 128.0f,
                  B = b * 255.0f - 128.0f;

                // Convert to CIE XYZ.
                F Y = (L + 16.0f) * (1/116.0f),
                  X = Y + A*(1/500.0f),
                  Z = Y - B*(1/200.0f);

                X = if_then_else(X*X*X > 0.008856f, X*X*X, (X - (16/116.0f)) * (1/7.787f));
                Y = if_then_else(Y*Y*Y > 0.008856f, Y*Y*Y, (Y - (16/116.0f)) * (1/7.787f));
                Z = if_then_else(Z*Z*Z > 0.008856f, Z*Z*Z, (Z - (16/116.0f)) * (1/7.787f));

                // Adjust to XYZD50 illuminant, and stuff back into r,g,b for the next op.
                r = X * 0.9642f;
                g = Y          ;
                b = Z * 0.8249f;
            } break;

            case Op_tf_r:{ r = apply_tf((const skcms_TransferFunction*)*args++, r); } break;
            case Op_tf_g:{ g = apply_tf((const skcms_TransferFunction*)*args++, g); } break;
            case Op_tf_b:{ b = apply_tf((const skcms_TransferFunction*)*args++, b); } break;
            case Op_tf_a:{ a = apply_tf((const skcms_TransferFunction*)*args++, a); } break;

            case Op_table_r: { r = table((const skcms_Curve*)*args++, r); } break;
            case Op_table_g: { g = table((const skcms_Curve*)*args++, g); } break;
            case Op_table_b: { b = table((const skcms_Curve*)*args++, b); } break;
            case Op_table_a: { a = table((const skcms_Curve*)*args++, a); } break;

            case Op_clut: {
                const skcms_A2B* a2b = (const skcms_A2B*) *args++;
                clut(a2b, &r,&g,&b,a);

                if (a2b->input_channels == 4) {
                    // CMYK is opaque.
                    a = F1;
                }
            } break;

    // Notice, from here on down the store_ ops all return, ending the loop.

            case Op_store_a8: {
                store(dst + 1*i, cast<U8>(to_fixed(a * 255)));
            } return;

            case Op_store_g8: {
                // g should be holding luminance (Y) (r,g,b ~~~> X,Y,Z)
                store(dst + 1*i, cast<U8>(to_fixed(g * 255)));
            } return;

            case Op_store_4444: {
                store<U16>(dst + 2*i, cast<U16>(to_fixed(r * 15) << 12)
                                    | cast<U16>(to_fixed(g * 15) <<  8)
                                    | cast<U16>(to_fixed(b * 15) <<  4)
                                    | cast<U16>(to_fixed(a * 15) <<  0));
            } return;

            case Op_store_565: {
                store<U16>(dst + 2*i, cast<U16>(to_fixed(r * 31) <<  0 )
                                    | cast<U16>(to_fixed(g * 63) <<  5 )
                                    | cast<U16>(to_fixed(b * 31) << 11 ));
            } return;

            case Op_store_888: {
                uint8_t* rgb = (uint8_t*)dst + 3*i;
            #if defined(USING_NEON_FP16)
                // See the explanation under USING_NEON below.  This is that doubled up.
                U16 R = to_fixed(r * 255),
                    G = to_fixed(g * 255),
                    B = to_fixed(b * 255);

                uint8x16x3_t v = {{ (uint8x16_t)R, (uint8x16_t)G, (uint8x16_t)B }};
                vst3q_lane_u8(rgb+ 0, v,  0);
                vst3q_lane_u8(rgb+ 3, v,  2);
                vst3q_lane_u8(rgb+ 6, v,  4);
                vst3q_lane_u8(rgb+ 9, v,  6);

                vst3q_lane_u8(rgb+12, v,  8);
                vst3q_lane_u8(rgb+15, v, 10);
                vst3q_lane_u8(rgb+18, v, 12);
                vst3q_lane_u8(rgb+21, v, 14);
            #elif defined(USING_NEON)
                // Same deal as load_888 but in reverse... we'll store using uint8x8x3_t, but
                // get there via U16 to save some instructions converting to float.  And just
                // like load_888, we'd prefer to go via U32 but for ARMv7 support.
                U16 R = cast<U16>(to_fixed(r * 255)),
                    G = cast<U16>(to_fixed(g * 255)),
                    B = cast<U16>(to_fixed(b * 255));

                uint8x8x3_t v = {{ (uint8x8_t)R, (uint8x8_t)G, (uint8x8_t)B }};
                vst3_lane_u8(rgb+0, v, 0);
                vst3_lane_u8(rgb+3, v, 2);
                vst3_lane_u8(rgb+6, v, 4);
                vst3_lane_u8(rgb+9, v, 6);
            #else
                store_3(rgb+0, cast<U8>(to_fixed(r * 255)) );
                store_3(rgb+1, cast<U8>(to_fixed(g * 255)) );
                store_3(rgb+2, cast<U8>(to_fixed(b * 255)) );
            #endif
            } return;

            case Op_store_8888: {
                store(dst + 4*i, cast<U32>(to_fixed(r * 255)) <<  0
                               | cast<U32>(to_fixed(g * 255)) <<  8
                               | cast<U32>(to_fixed(b * 255)) << 16
                               | cast<U32>(to_fixed(a * 255)) << 24);
            } return;

            case Op_store_1010102: {
                store(dst + 4*i, cast<U32>(to_fixed(r * 1023)) <<  0
                               | cast<U32>(to_fixed(g * 1023)) << 10
                               | cast<U32>(to_fixed(b * 1023)) << 20
                               | cast<U32>(to_fixed(a *    3)) << 30);
            } return;

            case Op_store_161616LE: {
                uintptr_t ptr = (uintptr_t)(dst + 6*i);
                assert( (ptr & 1) == 0 );                // The dst pointer must be 2-byte aligned
                uint16_t* rgb = (uint16_t*)ptr;          // for this cast to uint16_t* to be safe.
            #if defined(USING_NEON_FP16)
                uint16x8x3_t v = {{
                    (uint16x8_t)U16_from_F(r),
                    (uint16x8_t)U16_from_F(g),
                    (uint16x8_t)U16_from_F(b),
                }};
                vst3q_u16(rgb, v);
            #elif defined(USING_NEON)
                uint16x4x3_t v = {{
                    (uint16x4_t)U16_from_F(r),
                    (uint16x4_t)U16_from_F(g),
                    (uint16x4_t)U16_from_F(b),
                }};
                vst3_u16(rgb, v);
            #else
                store_3(rgb+0, U16_from_F(r));
                store_3(rgb+1, U16_from_F(g));
                store_3(rgb+2, U16_from_F(b));
            #endif

            } return;

            case Op_store_16161616LE: {
                uintptr_t ptr = (uintptr_t)(dst + 8*i);
                assert( (ptr & 1) == 0 );               // The dst pointer must be 2-byte aligned
                uint16_t* rgba = (uint16_t*)ptr;        // for this cast to uint16_t* to be safe.
            #if defined(USING_NEON_FP16)
                uint16x8x4_t v = {{
                    (uint16x8_t)U16_from_F(r),
                    (uint16x8_t)U16_from_F(g),
                    (uint16x8_t)U16_from_F(b),
                    (uint16x8_t)U16_from_F(a),
                }};
                vst4q_u16(rgba, v);
            #elif defined(USING_NEON)
                uint16x4x4_t v = {{
                    (uint16x4_t)U16_from_F(r),
                    (uint16x4_t)U16_from_F(g),
                    (uint16x4_t)U16_from_F(b),
                    (uint16x4_t)U16_from_F(a),
                }};
                vst4_u16(rgba, v);
            #else
                U64 px = cast<U64>(to_fixed(r * 65535)) <<  0
                       | cast<U64>(to_fixed(g * 65535)) << 16
                       | cast<U64>(to_fixed(b * 65535)) << 32
                       | cast<U64>(to_fixed(a * 65535)) << 48;
                store(rgba, px);
            #endif
            } return;

            case Op_store_161616BE: {
                uintptr_t ptr = (uintptr_t)(dst + 6*i);
                assert( (ptr & 1) == 0 );                // The dst pointer must be 2-byte aligned
                uint16_t* rgb = (uint16_t*)ptr;          // for this cast to uint16_t* to be safe.
            #if defined(USING_NEON_FP16)
                uint16x8x3_t v = {{
                    (uint16x8_t)swap_endian_16(U16_from_F(r)),
                    (uint16x8_t)swap_endian_16(U16_from_F(g)),
                    (uint16x8_t)swap_endian_16(U16_from_F(b)),
                }};
                vst3q_u16(rgb, v);
            #elif defined(USING_NEON)
                uint16x4x3_t v = {{
                    (uint16x4_t)swap_endian_16(cast<U16>(U16_from_F(r))),
                    (uint16x4_t)swap_endian_16(cast<U16>(U16_from_F(g))),
                    (uint16x4_t)swap_endian_16(cast<U16>(U16_from_F(b))),
                }};
                vst3_u16(rgb, v);
            #else
                U32 R = to_fixed(r * 65535),
                    G = to_fixed(g * 65535),
                    B = to_fixed(b * 65535);
                store_3(rgb+0, cast<U16>((R & 0x00ff) << 8 | (R & 0xff00) >> 8) );
                store_3(rgb+1, cast<U16>((G & 0x00ff) << 8 | (G & 0xff00) >> 8) );
                store_3(rgb+2, cast<U16>((B & 0x00ff) << 8 | (B & 0xff00) >> 8) );
            #endif

            } return;

            case Op_store_16161616BE: {
                uintptr_t ptr = (uintptr_t)(dst + 8*i);
                assert( (ptr & 1) == 0 );               // The dst pointer must be 2-byte aligned
                uint16_t* rgba = (uint16_t*)ptr;        // for this cast to uint16_t* to be safe.
            #if defined(USING_NEON_FP16)
                uint16x8x4_t v = {{
                    (uint16x8_t)swap_endian_16(U16_from_F(r)),
                    (uint16x8_t)swap_endian_16(U16_from_F(g)),
                    (uint16x8_t)swap_endian_16(U16_from_F(b)),
                    (uint16x8_t)swap_endian_16(U16_from_F(a)),
                }};
                vst4q_u16(rgba, v);
            #elif defined(USING_NEON)
                uint16x4x4_t v = {{
                    (uint16x4_t)swap_endian_16(cast<U16>(U16_from_F(r))),
                    (uint16x4_t)swap_endian_16(cast<U16>(U16_from_F(g))),
                    (uint16x4_t)swap_endian_16(cast<U16>(U16_from_F(b))),
                    (uint16x4_t)swap_endian_16(cast<U16>(U16_from_F(a))),
                }};
                vst4_u16(rgba, v);
            #else
                U64 px = cast<U64>(to_fixed(r * 65535)) <<  0
                       | cast<U64>(to_fixed(g * 65535)) << 16
                       | cast<U64>(to_fixed(b * 65535)) << 32
                       | cast<U64>(to_fixed(a * 65535)) << 48;
                store(rgba, swap_endian_16x4(px));
            #endif
            } return;

            case Op_store_hhh: {
                uintptr_t ptr = (uintptr_t)(dst + 6*i);
                assert( (ptr & 1) == 0 );                // The dst pointer must be 2-byte aligned
                uint16_t* rgb = (uint16_t*)ptr;          // for this cast to uint16_t* to be safe.

                U16 R = Half_from_F(r),
                    G = Half_from_F(g),
                    B = Half_from_F(b);
            #if defined(USING_NEON_FP16)
                uint16x8x3_t v = {{
                    (uint16x8_t)R,
                    (uint16x8_t)G,
                    (uint16x8_t)B,
                }};
                vst3q_u16(rgb, v);
            #elif defined(USING_NEON)
                uint16x4x3_t v = {{
                    (uint16x4_t)R,
                    (uint16x4_t)G,
                    (uint16x4_t)B,
                }};
                vst3_u16(rgb, v);
            #else
                store_3(rgb+0, R);
                store_3(rgb+1, G);
                store_3(rgb+2, B);
            #endif
            } return;

            case Op_store_hhhh: {
                uintptr_t ptr = (uintptr_t)(dst + 8*i);
                assert( (ptr & 1) == 0 );                // The dst pointer must be 2-byte aligned
                uint16_t* rgba = (uint16_t*)ptr;         // for this cast to uint16_t* to be safe.

                U16 R = Half_from_F(r),
                    G = Half_from_F(g),
                    B = Half_from_F(b),
                    A = Half_from_F(a);
            #if defined(USING_NEON_FP16)
                uint16x8x4_t v = {{
                    (uint16x8_t)R,
                    (uint16x8_t)G,
                    (uint16x8_t)B,
                    (uint16x8_t)A,
                }};
                vst4q_u16(rgba, v);
            #elif defined(USING_NEON)
                uint16x4x4_t v = {{
                    (uint16x4_t)R,
                    (uint16x4_t)G,
                    (uint16x4_t)B,
                    (uint16x4_t)A,
                }};
                vst4_u16(rgba, v);
            #else
                store(rgba, cast<U64>(R) <<  0
                          | cast<U64>(G) << 16
                          | cast<U64>(B) << 32
                          | cast<U64>(A) << 48);
            #endif

            } return;

            case Op_store_fff: {
                uintptr_t ptr = (uintptr_t)(dst + 12*i);
                assert( (ptr & 3) == 0 );                // The dst pointer must be 4-byte aligned
                float* rgb = (float*)ptr;                // for this cast to float* to be safe.
            #if defined(USING_NEON_FP16)
                float32x4x3_t lo = {{
                    vcvt_f32_f16(vget_low_f16(r)),
                    vcvt_f32_f16(vget_low_f16(g)),
                    vcvt_f32_f16(vget_low_f16(b)),
                }}, hi = {{
                    vcvt_f32_f16(vget_high_f16(r)),
                    vcvt_f32_f16(vget_high_f16(g)),
                    vcvt_f32_f16(vget_high_f16(b)),
                }};
                vst3q_f32(rgb +  0, lo);
                vst3q_f32(rgb + 12, hi);
            #elif defined(USING_NEON)
                float32x4x3_t v = {{
                    (float32x4_t)r,
                    (float32x4_t)g,
                    (float32x4_t)b,
                }};
                vst3q_f32(rgb, v);
            #else
                store_3(rgb+0, r);
                store_3(rgb+1, g);
                store_3(rgb+2, b);
            #endif
            } return;

            case Op_store_ffff: {
                uintptr_t ptr = (uintptr_t)(dst + 16*i);
                assert( (ptr & 3) == 0 );                // The dst pointer must be 4-byte aligned
                float* rgba = (float*)ptr;               // for this cast to float* to be safe.
            #if defined(USING_NEON_FP16)
                float32x4x4_t lo = {{
                    vcvt_f32_f16(vget_low_f16(r)),
                    vcvt_f32_f16(vget_low_f16(g)),
                    vcvt_f32_f16(vget_low_f16(b)),
                    vcvt_f32_f16(vget_low_f16(a)),
                }}, hi = {{
                    vcvt_f32_f16(vget_high_f16(r)),
                    vcvt_f32_f16(vget_high_f16(g)),
                    vcvt_f32_f16(vget_high_f16(b)),
                    vcvt_f32_f16(vget_high_f16(a)),
                }};
                vst4q_f32(rgba +  0, lo);
                vst4q_f32(rgba + 16, hi);
            #elif defined(USING_NEON)
                float32x4x4_t v = {{
                    (float32x4_t)r,
                    (float32x4_t)g,
                    (float32x4_t)b,
                    (float32x4_t)a,
                }};
                vst4q_f32(rgba, v);
            #else
                store_4(rgba+0, r);
                store_4(rgba+1, g);
                store_4(rgba+2, b);
                store_4(rgba+3, a);
            #endif
            } return;
        }
    }
}


static void run_program(const Op* program, const void** arguments,
                        const char* src, char* dst, int n,
                        const size_t src_bpp, const size_t dst_bpp) {
    int i = 0;
    while (n >= N) {
        exec_ops(program, arguments, src, dst, i);
        i += N;
        n -= N;
    }
    if (n > 0) {
        char tmp[4*4*N] = {0};

        memcpy(tmp, (const char*)src + (size_t)i*src_bpp, (size_t)n*src_bpp);
        exec_ops(program, arguments, tmp, tmp, 0);
        memcpy((char*)dst + (size_t)i*dst_bpp, tmp, (size_t)n*dst_bpp);
    }
}

// Clean up any #defines we may have set so that we can be #included again.
#if defined(USING_AVX)
    #undef  USING_AVX
#endif
#if defined(USING_AVX_F16C)
    #undef  USING_AVX_F16C
#endif
#if defined(USING_AVX2)
    #undef  USING_AVX2
#endif
#if defined(USING_AVX512F)
    #undef  USING_AVX512F
#endif

#if defined(USING_NEON)
    #undef  USING_NEON
#endif
#if defined(USING_NEON_F16C)
    #undef  USING_NEON_F16C
#endif
#if defined(USING_NEON_FP16)
    #undef  USING_NEON_FP16
#endif

#undef FALLTHROUGH
